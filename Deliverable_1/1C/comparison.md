# Σύγκριση Pipelines Ανασύνθεσης (Άσκηση 1C)

Το παρόν έγγραφο συγκρίνει τις τρεις προσεγγίσεις που υλοποιήθηκαν στην Άσκηση 1B για την αυτόματη ανασύνθεση δύο δοθέντων κειμένων. Κάθε pipeline χρησιμοποιεί διαφορετική βιβλιοθήκη και στρατηγική.

---

## Pipeline 1: SBERT + Semantic Retrieval (PAWS-Wiki, σε επίπεδο clause)

### Περιγραφή
- Χρησιμοποιήθηκε το μοντέλο SBERT (`paraphrase-MiniLM-L6-v2`) σε συνδυασμό με παραφράσεις από το PAWS-Wiki.
- Αρχικά δοκιμάστηκαν εκδόσεις πλήρους πρότασης και διαφορετικά datasets (PAWS, QQP, MSRPC), χωρίς επιτυχείς αντικαταστάσεις.
- Η τελική εκδοχή λειτουργεί σε επίπεδο clause και καταγράφει λίγες αλλά εύστοχες αλλαγές.

### Συμπεριφορά
- Το SBERT αποφεύγει οποιαδήποτε αντικατάσταση αν εντοπίσει υφολογική ή σημασιολογική αναντιστοιχία.
- Ακόμα και με χαμηλότερα thresholds και χαλαρωμένα φίλτρα, το μοντέλο απέρριπτε προτάσεις που δεν ταίριαζαν ακριβώς στο ύφος.
- Η συμπεριφορά αυτή αντικατοπτρίζει την υψηλή ακρίβεια και στιλιστική αυστηρότητα του μοντέλου.

---

## Pipeline 2: SpaCy + GloVe (Rule-Based Repair)

### Περιγραφή
- Χρησιμοποιήθηκε το `en_core_web_lg` μοντέλο του SpaCy και εφαρμόστηκαν χειροποίητοι κανόνες για συντακτικές διορθώσεις.
- Δεν χρησιμοποιήθηκαν προτάσεις-υποψήφιες από dataset. Όλη η επεξεργασία βασίστηκε σε POS tagging και dependency parsing.

### Συμπεριφορά
- Το pipeline διόρθωσε γραμματικά λάθη όπως «final discuss» → «final discussion».
- Οι παρεμβάσεις είναι ελάχιστες, αλλά βοηθούν στην ανάγνωση και καθαρότητα.
- Δεν εφαρμόστηκε διάσπαση σε clauses, καθώς το SpaCy ήδη επεξεργάζεται εσωτερική συντακτική δομή.

---

## Pipeline 3: FastText + QQP (Clause-Level Cosine Similarity)

### Περιγραφή
- Χρησιμοποιήθηκαν FastText embeddings (`fasttext-wiki-news-subwords-300`) και παραφράσεις από το QQP.
- Πραγματοποιήθηκε αναζήτηση παραφράσεων με βάση cosine similarity μεταξύ προτάσεων ή clauses.

### Συμπεριφορά
- Παρήγαγε περισσότερες αλλαγές από τα άλλα pipelines.
- Παρόλα αυτά, αρκετές αντικαταστάσεις ήταν άστοχες θεματικά ή εκτός περιεχομένου (π.χ. «Is it bad to eat eggs everyday...»).
- Το clause-level αύξησε τη δραστηριότητα, αλλά δεν έλυσε το βασικό πρόβλημα έλλειψης σημασιολογικού ελέγχου.

---

## Συνοπτική Σύγκριση

| Pipeline        | Προσέγγιση         | Αλλαγές       | Ποιότητα Αλλαγών           | Υφολογική συνέπεια |
|-----------------|--------------------|---------------|-----------------------------|---------------------|
| SBERT + PAWS    | Αναζήτηση clause   | Λίγες         | Υψηλής ποιότητας, συντηρητικές | ✅ Πολύ υψηλή        |
| SpaCy + GloVe   | Κανόνες + POS      | Πολύ λίγες    | Ακριβείς γραμματικές        | ✅ Υψηλή             |
| FastText + QQP  | Cosine (clauses)   | Περισσότερες  | Συχνά άστοχες / off-topic   | ❌ Ασταθής           |

---

## Συμπεράσματα

- Το SBERT παρουσίασε εξαιρετική ακρίβεια και απέφυγε παρανοήσεις, αλλά έχει χαμηλό recall (λιγότερες αλλαγές).
- Το SpaCy είναι ιδανικό για εστιασμένες διορθώσεις χωρίς αλλαγή νοήματος.
- Το FastText προσφέρει υψηλότερη κάλυψη (recall) αλλά θυσιάζει τη σημασιολογική συνέπεια.

Καμία προσέγγιση δεν είναι πλήρης από μόνη της· κάθε pipeline επιδεικνύει διαφορετικό συμβιβασμό μεταξύ ακρίβειας, κάλυψης και υφολογικής σταθερότητας.

